import json
from typing import List, Dict, Any

# AWS Configuration
region = "us-east-1"  # Update with your region
account_id = "YOUR_ACCOUNT_ID"

# Define Lambda ARN for your quantitative tools
quantitative_tools_arn = f"arn:aws:lambda:{region}:{account_id}:function:quantitative_analysis_tools"

# LLM Configuration (NVIDIA NIM for optional offloading)
LLM = {
    "provider": "nvidia_nim",  # or "bedrock"
    "model_id": "meta/llama-3.1-70b-instruct",  # NVIDIA NIM model
    "temperature": 0.3,  # Lower for financial analysis
    "max_tokens": 1024
}

# ============================================================
# QUANTITATIVE ANALYSIS AGENT
# ============================================================

quantitative_analysis_agent = Agent.create(
    name="quantitative_analysis_agent",
    role="Quantitative Financial Analyst",
    goal="""Retrieve real-time and historical stock data, calculate advanced 
    financial metrics, perform technical analysis, and optimize portfolios 
    using modern portfolio theory.""",
    
    instructions="""You are a Quantitative Financial Analyst specializing in data-driven investment analysis.

**Your Core Responsibilities:**

1. **Data Retrieval**
   - Fetch real-time and historical stock prices using Yahoo Finance API
   - Retrieve fundamental data (P/E ratio, market cap, dividend yield, etc.)
   - Handle multiple tickers simultaneously
   - Validate and clean financial data

2. **Technical Analysis**
   - Calculate moving averages (SMA, EMA)
   - Compute momentum indicators (RSI, MACD, Stochastic)
   - Analyze volatility (standard deviation, Bollinger Bands, ATR)
   - Identify support/resistance levels and trends

3. **Fundamental Metrics**
   - Calculate valuation ratios (P/E, P/B, PEG)
   - Analyze profitability metrics (ROE, ROA, profit margins)
   - Compute growth rates (revenue, earnings)
   - Assess financial health indicators

4. **Portfolio Optimization**
   - Apply Modern Portfolio Theory (Markowitz optimization)
   - Calculate efficient frontier
   - Optimize for Sharpe ratio maximization
   - Consider risk tolerance and constraints
   - Require minimum 3 tickers for optimization

5. **Risk Analysis**
   - Calculate Value at Risk (VaR)
   - Compute beta and correlation matrices
   - Analyze drawdown metrics
   - Assess portfolio diversification

6. **Mathematical Computation Strategy**
   - Perform all calculations locally for speed and cost efficiency
   - Use LLM offloading ONLY for:
     * Interpreting complex patterns in data
     * Generating narrative explanations of metrics
     * Providing context for unusual market conditions
   - Always validate LLM interpretations against computed data

**Operational Rules:**

- Always retrieve stock data BEFORE performing any calculations
- Validate data quality (check for missing values, outliers, data gaps)
- If API fails, retry up to 3 times with exponential backoff
- For portfolio optimization, enforce minimum 3-ticker rule
- Return structured JSON output with all metrics clearly labeled
- Include confidence scores and data quality indicators
- Flag any anomalies or data quality issues
- Respect API rate limits (Yahoo Finance: ~2000 requests/hour)

**Error Handling:**
- Invalid ticker → Return error with suggestion to verify symbol
- Insufficient data → Specify minimum required data points
- API timeout → Retry with backoff, then return cached data if available
- Rate limit hit → Queue request and inform user of delay
- Missing data points → Use interpolation only if gap < 3 days, otherwise flag

**Output Format:**
Always return results as structured JSON:
{
  "tickers": [...],
  "data_quality": {"score": 0-1, "issues": [...]},
  "price_data": {...},
  "technical_indicators": {...},
  "fundamental_metrics": {...},
  "portfolio_optimization": {...},
  "risk_metrics": {...},
  "recommendations": [...],
  "timestamp": "ISO-8601"
}
""",
    
    tools=[
        # Tool 1: Stock Data Retrieval
        {
            "code": quantitative_tools_arn,
            "definition": {
                "name": "fetch_stock_data",
                "description": "Retrieves comprehensive stock data including price history, volume, and basic fundamentals from Yahoo Finance API.",
                "parameters": {
                    "ticker": {
                        "description": "Stock ticker symbol (e.g., 'AAPL', 'MSFT')",
                        "type": "string",
                        "required": True,
                    },
                    "period": {
                        "description": "Time period: '1mo', '3mo', '6mo', '1y', '2y', '5y'",
                        "type": "string",
                        "required": False,
                    },
                    "interval": {
                        "description": "Data interval: '1d', '1wk', '1mo'",
                        "type": "string",
                        "required": False,
                    }
                },
            },
        },
        
        # Tool 2: Technical Indicators Calculation
        {
            "code": quantitative_tools_arn,
            "definition": {
                "name": "calculate_technical_indicators",
                "description": "Computes technical analysis indicators including moving averages, RSI, MACD, Bollinger Bands, and volatility metrics.",
                "parameters": {
                    "price_data": {
                        "description": "JSON string containing historical price data with 'date', 'close', 'high', 'low', 'volume' fields",
                        "type": "string",
                        "required": True,
                    },
                    "indicators": {
                        "description": "Comma-separated list of indicators to calculate: 'sma', 'ema', 'rsi', 'macd', 'bollinger', 'atr'",
                        "type": "string",
                        "required": False,
                    }
                },
            },
        },
        
        # Tool 3: Fundamental Analysis
        {
            "code": quantitative_tools_arn,
            "definition": {
                "name": "analyze_fundamentals",
                "description": "Retrieves and analyzes fundamental financial metrics including P/E ratio, market cap, dividend yield, ROE, and growth rates.",
                "parameters": {
                    "ticker": {
                        "description": "Stock ticker symbol",
                        "type": "string",
                        "required": True,
                    },
                    "metrics": {
                        "description": "Comma-separated metrics: 'valuation', 'profitability', 'growth', 'financial_health'",
                        "type": "string",
                        "required": False,
                    }
                },
            },
        },
        
        # Tool 4: Portfolio Optimization
        {
            "code": quantitative_tools_arn,
            "definition": {
                "name": "optimize_portfolio",
                "description": "Performs Modern Portfolio Theory optimization to find optimal asset allocation for maximum Sharpe ratio. Requires minimum 3 tickers.",
                "parameters": {
                    "tickers": {
                        "description": "Comma-separated list of stock tickers (minimum 3 required)",
                        "type": "string",
                        "required": True,
                    },
                    "price_data": {
                        "description": "JSON object with tickers as keys, each containing historical price arrays",
                        "type": "string",
                        "required": True,
                    },
                    "optimization_target": {
                        "description": "Optimization goal: 'max_sharpe', 'min_volatility', 'max_return'",
                        "type": "string",
                        "required": False,
                    },
                    "constraints": {
                        "description": "JSON string with constraints like max position size, sector limits",
                        "type": "string",
                        "required": False,
                    }
                },
            },
        },
        
        # Tool 5: Risk Analysis
        {
            "code": quantitative_tools_arn,
            "definition": {
                "name": "calculate_risk_metrics",
                "description": "Computes risk metrics including Value at Risk (VaR), beta, correlation matrix, maximum drawdown, and Sharpe ratio.",
                "parameters": {
                    "price_data": {
                        "description": "JSON string with historical price data",
                        "type": "string",
                        "required": True,
                    },
                    "portfolio_weights": {
                        "description": "JSON object with ticker weights (optional, for portfolio-level risk)",
                        "type": "string",
                        "required": False,
                    },
                    "confidence_level": {
                        "description": "Confidence level for VaR calculation (e.g., 0.95, 0.99)",
                        "type": "string",
                        "required": False,
                    }
                },
            },
        },
        
        # Tool 6: LLM-Powered Interpretation (Optional Offloading)
        {
            "code": quantitative_tools_arn,
            "definition": {
                "name": "interpret_metrics_with_llm",
                "description": "Uses NVIDIA NIM LLM to provide contextual interpretation of calculated metrics and identify patterns. Only use after computing numerical metrics.",
                "parameters": {
                    "metrics_data": {
                        "description": "JSON string containing all calculated metrics",
                        "type": "string",
                        "required": True,
                    },
                    "market_context": {
                        "description": "Additional market context or recent news (optional)",
                        "type": "string",
                        "required": False,
                    },
                    "analysis_focus": {
                        "description": "Focus area: 'trends', 'anomalies', 'opportunities', 'risks'",
                        "type": "string",
                        "required": False,
                    }
                },
            },
        },
        
        # Tool 7: Data Quality Validation
        {
            "code": quantitative_tools_arn,
            "definition": {
                "name": "validate_data_quality",
                "description": "Validates financial data for completeness, accuracy, and consistency. Identifies gaps, outliers, and potential errors.",
                "parameters": {
                    "price_data": {
                        "description": "JSON string with price data to validate",
                        "type": "string",
                        "required": True,
                    },
                    "validation_rules": {
                        "description": "JSON string with validation criteria",
                        "type": "string",
                        "required": False,
                    }
                },
            },
        },
    ],
    
    llm=LLM,
)
import json
import yfinance as yf
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from scipy.optimize import minimize
from scipy import stats
import requests
import time

# For LLM offloading
NVIDIA_NIM_API_KEY = "YOUR_NVIDIA_API_KEY"
NVIDIA_NIM_ENDPOINT = "https://integrate.api.nvidia.com/v1/chat/completions"

def lambda_handler(event, context):
    """
    Main Lambda handler for Quantitative Analysis Agent tools
    """
    tool_name = event.get('tool_name')
    parameters = event.get('parameters', {})
    
    tool_functions = {
        'fetch_stock_data': fetch_stock_data,
        'calculate_technical_indicators': calculate_technical_indicators,
        'analyze_fundamentals': analyze_fundamentals,
        'optimize_portfolio': optimize_portfolio,
        'calculate_risk_metrics': calculate_risk_metrics,
        'interpret_metrics_with_llm': interpret_metrics_with_llm,
        'validate_data_quality': validate_data_quality,
    }
    
    if tool_name in tool_functions:
        try:
            result = tool_functions[tool_name](parameters)
            return {
                'statusCode': 200,
                'body': json.dumps(result, default=str)
            }
        except Exception as e:
            return {
                'statusCode': 500,
                'body': json.dumps({
                    'error': str(e),
                    'tool': tool_name,
                    'parameters': parameters
                })
            }
    else:
        return {
            'statusCode': 400,
            'body': json.dumps({'error': f'Unknown tool: {tool_name}'})
        }


# ============================================================
# TOOL 1: FETCH STOCK DATA
# ============================================================

def fetch_stock_data(params: Dict) -> Dict:
    """
    Retrieves stock data from Yahoo Finance with retry logic
    """
    ticker = params.get('ticker', '').upper()
    period = params.get('period', '1y')
    interval = params.get('interval', '1d')
    
    if not ticker:
        raise ValueError("Ticker symbol is required")
    
    # Retry logic for API reliability
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            stock = yf.Ticker(ticker)
            
            # Fetch historical price data
            hist = stock.history(period=period, interval=interval)
            
            if hist.empty:
                raise ValueError(f"No data found for ticker: {ticker}")
            
            # Fetch company info
            info = stock.info
            
            # Convert to JSON-serializable format
            price_data = {
                'dates': hist.index.strftime('%Y-%m-%d').tolist(),
                'open': hist['Open'].tolist(),
                'high': hist['High'].tolist(),
                'low': hist['Low'].tolist(),
                'close': hist['Close'].tolist(),
                'volume': hist['Volume'].tolist(),
            }
            
            # Extract key fundamental data
            fundamentals = {
                'market_cap': info.get('marketCap'),
                'pe_ratio': info.get('trailingPE'),
                'forward_pe': info.get('forwardPE'),
                'peg_ratio': info.get('pegRatio'),
                'price_to_book': info.get('priceToBook'),
                'dividend_yield': info.get('dividendYield'),
                'beta': info.get('beta'),
                'fifty_two_week_high': info.get('fiftyTwoWeekHigh'),
                'fifty_two_week_low': info.get('fiftyTwoWeekLow'),
                'current_price': info.get('currentPrice'),
                'company_name': info.get('longName'),
                'sector': info.get('sector'),
                'industry': info.get('industry'),
            }
            
            return {
                'ticker': ticker,
                'price_data': price_data,
                'fundamentals': fundamentals,
                'data_points': len(hist),
                'period': period,
                'interval': interval,
                'retrieved_at': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(retry_delay * (2 ** attempt))  # Exponential backoff
                continue
            else:
                raise Exception(f"Failed to fetch data for {ticker} after {max_retries} attempts: {str(e)}")


# ============================================================
# TOOL 2: CALCULATE TECHNICAL INDICATORS
# ============================================================

def calculate_technical_indicators(params: Dict) -> Dict:
    """
    Computes technical analysis indicators
    """
    price_data = json.loads(params.get('price_data', '{}'))
    indicators_str = params.get('indicators', 'sma,ema,rsi,macd')
    indicators = [i.strip() for i in indicators_str.split(',')]
    
    # Convert to DataFrame
    df = pd.DataFrame({
        'date': pd.to_datetime(price_data['dates']),
        'close': price_data['close'],
        'high': price_data['high'],
        'low': price_data['low'],
        'volume': price_data['volume']
    })
    df.set_index('date', inplace=True)
    
    results = {}
    
    # Simple Moving Averages
    if 'sma' in indicators:
        results['sma_20'] = df['close'].rolling(window=20).mean().tolist()
        results['sma_50'] = df['close'].rolling(window=50).mean().tolist()
        results['sma_200'] = df['close'].rolling(window=200).mean().tolist()
    
    # Exponential Moving Averages
    if 'ema' in indicators:
        results['ema_12'] = df['close'].ewm(span=12, adjust=False).mean().tolist()
        results['ema_26'] = df['close'].ewm(span=26, adjust=False).mean().tolist()
    
    # Relative Strength Index (RSI)
    if 'rsi' in indicators:
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        results['rsi'] = rsi.tolist()
        results['rsi_signal'] = 'overbought' if rsi.iloc[-1] > 70 else 'oversold' if rsi.iloc[-1] < 30 else 'neutral'
    
    # MACD
    if 'macd' in indicators:
        ema_12 = df['close'].ewm(span=12, adjust=False).mean()
        ema_26 = df['close'].ewm(span=26, adjust=False).mean()
        macd = ema_12 - ema_26
        signal = macd.ewm(span=9, adjust=False).mean()
        histogram = macd - signal
        
        results['macd'] = macd.tolist()
        results['macd_signal'] = signal.tolist()
        results['macd_histogram'] = histogram.tolist()
    
    # Bollinger Bands
    if 'bollinger' in indicators:
        sma_20 = df['close'].rolling(window=20).mean()
        std_20 = df['close'].rolling(window=20).std()
        
        results['bollinger_upper'] = (sma_20 + (std_20 * 2)).tolist()
        results['bollinger_middle'] = sma_20.tolist()
        results['bollinger_lower'] = (sma_20 - (std_20 * 2)).tolist()
    
    # Average True Range (ATR) - Volatility
    if 'atr' in indicators:
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        atr = true_range.rolling(14).mean()
        
        results['atr'] = atr.tolist()
    
    # Volatility (Standard Deviation)
    results['volatility_20d'] = df['close'].pct_change().rolling(window=20).std().tolist()
    results['volatility_current'] = float(df['close'].pct_change().rolling(window=20).std().iloc[-1])
    
    return {
        'indicators': results,
        'dates': df.index.strftime('%Y-%m-%d').tolist(),
        'calculated_at': datetime.utcnow().isoformat()
    }


# ============================================================
# TOOL 3: ANALYZE FUNDAMENTALS
# ============================================================

def analyze_fundamentals(params: Dict) -> Dict:
    """
    Analyzes fundamental financial metrics
    """
    ticker = params.get('ticker', '').upper()
    metrics_str = params.get('metrics', 'valuation,profitability,growth')
    metrics = [m.strip() for m in metrics_str.split(',')]
    
    stock = yf.Ticker(ticker)
    info = stock.info
    
    analysis = {
        'ticker': ticker,
        'company_name': info.get('longName'),
        'sector': info.get('sector'),
        'industry': info.get('industry'),
    }
    
    # Valuation Metrics
    if 'valuation' in metrics:
        analysis['valuation'] = {
            'market_cap': info.get('marketCap'),
            'enterprise_value': info.get('enterpriseValue'),
            'pe_ratio': info.get('trailingPE'),
            'forward_pe': info.get('forwardPE'),
            'peg_ratio': info.get('pegRatio'),
            'price_to_sales': info.get('priceToSalesTrailing12Months'),
            'price_to_book': info.get('priceToBook'),
            'ev_to_revenue': info.get('enterpriseToRevenue'),
            'ev_to_ebitda': info.get('enterpriseToEbitda'),
        }
    
    # Profitability Metrics
    if 'profitability' in metrics:
        analysis['profitability'] = {
            'profit_margins': info.get('profitMargins'),
            'operating_margins': info.get('operatingMargins'),
            'return_on_assets': info.get('returnOnAssets'),
            'return_on_equity': info.get('returnOnEquity'),
            'gross_margins': info.get('grossMargins'),
        }
    
    # Growth Metrics
    if 'growth' in metrics:
        analysis['growth'] = {
            'revenue_growth': info.get('revenueGrowth'),
            'earnings_growth': info.get('earningsGrowth'),
            'earnings_quarterly_growth': info.get('earningsQuarterlyGrowth'),
        }
    
    # Financial Health
    if 'financial_health' in metrics:
        analysis['financial_health'] = {
            'current_ratio': info.get('currentRatio'),
            'quick_ratio': info.get('quickRatio'),
            'debt_to_equity': info.get('debtToEquity'),
            'total_cash': info.get('totalCash'),
            'total_debt': info.get('totalDebt'),
            'free_cash_flow': info.get('freeCashflow'),
        }
    
    return analysis


# ============================================================
# TOOL 4: PORTFOLIO OPTIMIZATION
# ============================================================

def optimize_portfolio(params: Dict) -> Dict:
    """
    Performs Modern Portfolio Theory optimization
    """
    tickers_str = params.get('tickers', '')
    tickers = [t.strip().upper() for t in tickers_str.split(',')]
    
    # Enforce minimum 3 tickers rule
    if len(tickers) < 3:
        raise ValueError(f"Portfolio optimization requires at least 3 tickers. You provided {len(tickers)}: {tickers}")
    
    price_data = json.loads(params.get('price_data', '{}'))
    optimization_target = params.get('optimization_target', 'max_sharpe')
    
    # Build returns DataFrame
    returns_data = {}
    for ticker in tickers:
        if ticker in price_data:
            prices = pd.Series(price_data[ticker]['close'])
            returns = prices.pct_change().dropna()
            returns_data[ticker] = returns
    
    returns_df = pd.DataFrame(returns_data)
    
    # Calculate expected returns and covariance matrix
    mean_returns = returns_df.mean() * 252  # Annualized
    cov_matrix = returns_df.cov() * 252  # Annualized
    
    num_assets = len(tickers)
    
    # Optimization objective functions
    def portfolio_stats(weights):
        portfolio_return = np.sum(mean_returns * weights)
        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        sharpe_ratio = portfolio_return / portfolio_volatility
        return portfolio_return, portfolio_volatility, sharpe_ratio
    
    def neg_sharpe(weights):
        return -portfolio_stats(weights)[2]
    
    def portfolio_variance(weights):
        return portfolio_stats(weights)[1]
    
    # Constraints and bounds
    constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # Weights sum to 1
    bounds = tuple((0, 1) for _ in range(num_assets))  # No short selling
    
    # Initial guess (equal weight)
    init_guess = num_assets * [1. / num_assets]
    
    # Optimize based on target
    if optimization_target == 'max_sharpe':
        opt_result = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=constraints)
    elif optimization_target == 'min_volatility':
        opt_result = minimize(portfolio_variance, init_guess, method='SLSQP', bounds=bounds, constraints=constraints)
    else:
        opt_result = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=constraints)
    
    optimal_weights = opt_result.x
    opt_return, opt_volatility, opt_sharpe = portfolio_stats(optimal_weights)
    
    # Create allocation dictionary
    allocation = {
        ticker: float(weight) 
        for ticker, weight in zip(tickers, optimal_weights)
    }
    
    return {
        'optimization_target': optimization_target,
        'optimal_allocation': allocation,
        'expected_annual_return': float(opt_return),
        'expected_annual_volatility': float(opt_volatility),
        'sharpe_ratio': float(opt_sharpe),
        'num_assets': num_assets,
        'diversification_score': float(1 - np.max(optimal_weights)),  # Lower max weight = better diversification
        'optimized_at': datetime.utcnow().isoformat()
    }


# ============================================================
# TOOL 5: CALCULATE RISK METRICS
# ============================================================

def calculate_risk_metrics(params: Dict) -> Dict:
    """
    Computes comprehensive risk metrics
    """
    price_data = json.loads(params.get('price_data', '{}'))
    portfolio_weights = json.loads(params.get('portfolio_weights', '{}')) if params.get('portfolio_weights') else None
    confidence_level = float(params.get('confidence_level', '0.95'))
    
    # Convert to returns
    returns_data = {}
    for ticker, data in price_data.items():
        prices = pd.Series(data['close'])
        returns = prices.pct_change().dropna()
        returns_data[ticker] = returns
    
    returns_df = pd.DataFrame(returns_data)
    
    # Calculate VaR (Value at Risk)
    if portfolio_weights:
        weights = np.array([portfolio_weights.get(t, 0) for t in returns_df.columns])
        portfolio_returns = returns_df.dot(weights)
    else:
        portfolio_returns = returns_df.mean(axis=1)
    
    var_parametric = np.percentile(portfolio_returns, (1 - confidence_level) * 100)
    
    # Maximum Drawdown
    cumulative_returns = (1 + portfolio_returns).cumprod()
    running_max = cumulative_returns.expanding().max()
    drawdown = (cumulative_returns - running_max) / running_max
    max_drawdown = drawdown.min()
    
    # Sharpe Ratio
    sharpe_ratio = (portfolio_returns.mean() * 252) / (portfolio_returns.std() * np.sqrt(252))
    
    # Correlation Matrix
    correlation_matrix = returns_df.corr().to_dict()
    
    # Beta (if SPY data available)
    beta_values = {}
    # This would require market index data - simplified here
    
    return {
        'value_at_risk': {
            'confidence_level': confidence_level,
            'var_1day': float(var_parametric),
            'var_1month': float(var_parametric * np.sqrt(21)),
        },
        'max_drawdown': float(max_drawdown),
        'sharpe_ratio': float(sharpe_ratio),
        'volatility_annual': float(portfolio_returns.std() * np.sqrt(252)),
        'correlation_matrix': correlation_matrix,
        'downside_deviation': float(portfolio_returns[portfolio_returns < 0].std() * np.sqrt(252)),
        'calculated_at': datetime.utcnow().isoformat()
    }


# ============================================================
# TOOL 6: LLM INTERPRETATION (NVIDIA NIM Offloading)
# ============================================================

def interpret_metrics_with_llm(params: Dict) -> Dict:
    """
    Uses NVIDIA NIM LLM for contextual interpretation
    """
    metrics_data = params.get('metrics_data', '{}')
    market_context = params.get('market_context', '')
    analysis_focus = params.get('analysis_focus', 'comprehensive')
    
    # Prepare prompt for LLM
    prompt = f"""You are a quantitative financial analyst. Analyze the following metrics and provide insights:

**Calculated Metrics:**
{metrics_data}

**Market Context:**
{market_context}

**Analysis Focus:** {analysis_focus}

Provide:
1. Key patterns and trends identified
2. Potential opportunities
3. Risk factors to consider
4. Actionable recommendations

Keep the analysis concise and data-driven."""

    headers = {
        "Authorization": f"Bearer {NVIDIA_NIM_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "meta/llama-3.1-70b-instruct",
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "max_tokens": 1024
    }
    
    try:
        response = requests.post(NVIDIA_NIM_ENDPOINT, headers=headers, json=payload)
        response.raise_for_status()
        
        result = response.json()
        interpretation = result['choices'][0]['message']['content']
        
        return {
            'interpretation': interpretation,
            'model_used': 'meta/llama-3.1-70b-instruct',
            'focus': analysis_focus,
            'generated_at': datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        return {
            'interpretation': 'LLM interpretation unavailable',
            'error': str(e),
            'fallback': 'Metrics calculated successfully. Manual interpretation required.'
        }


# ============================================================
# TOOL 7: DATA QUALITY VALIDATION
# ============================================================

def validate_data_quality(params: Dict) -> Dict:
    """
    Validates financial data quality
    """
    price_data = json.loads(params.get('price_data', '{}'))
    
    df = pd.DataFrame({
        'close': price_data['close'],
        'high': price_data['high'],
        'low': price_data['low'],
        'volume': price_data['volume']
    })
    
    issues = []
    
    # Check for missing values
    missing_count = df.isnull().sum().sum()
    if missing_count > 0:
        issues.append(f"Missing {missing_count} data points")
    
    # Check for zero/negative prices
    if (df['close'] <= 0).any():
        issues.append("Zero or negative prices detected")
    
    # Check for extreme price movements (>20% in one day)
    returns = df['close'].pct_change()
    extreme_moves = returns[abs(returns) > 0.20].count()
    if extreme_moves > 0:
        issues.append(f"{extreme_moves} extreme price movements (>20%) detected")
    
    # Check for data gaps
    dates = pd.to_datetime(price_data['dates'])
    date_diffs = dates.diff()
    gaps = (date_diffs > pd.Timedelta(days=4)).sum()  # More than weekend gap
    if gaps > 0:
        issues.append(f"{gaps} data gaps detected")
    
    # Data quality score
    quality_score = max(0, 1.0 - (len(issues) * 0.15))
    
    return {
        'quality_score': quality_score,
        'data_points': len(df),
        'issues': issues,
        'status': 'good' if quality_score > 0.8 else 'acceptable' if quality_score > 0.6 else 'poor',
        'validated_at': datetime.utcnow().isoformat()
    }
